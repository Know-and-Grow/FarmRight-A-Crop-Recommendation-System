# -*- coding: utf-8 -*-
"""data preprocessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UWQi1gayh8im4Tnb_Ce8xAMA4VcW9Mjf

### Cloning Git Repository
"""

# Clone your dataset repository
!git clone https://github.com/Know-and-Grow/Know-and-Grow.git

"""# Creating Weather Datafiles using API"""

# Importing  Python Libraries
import csv
import pandas as pd
import requests
import numpy as np

# Get the Centroids data set - containing geo-coordinates of each district of India
coord=pd.read_csv('/content/Know-and-Grow/Datasets/centroids.csv')

coord.shape

# dropping Null values in Centroids
# coord.isnull().sum()
coord = coord.dropna(how='any',axis=0)
coord.isnull().sum()
coord.shape[0]

coord.head()

coord['State'][coord.shape[1]]

# Get Rainfall dataset
with open('temp.csv', 'w') as t, open ('rainfall.csv', 'w') as r:
  writer1 = csv.writer(t)
  writer2 = csv.writer(r)

  columns=['State','District',
 'PARAMETER',
 'YEAR',
 'JAN',
 'FEB',
 'MAR',
 'APR',
 'MAY',
 'JUN',
 'JUL',
 'AUG',
 'SEP',
 'OCT',
 'NOV',
 'DEC',
 'ANN'] 

  
  writer1.writerow(columns)
  writer2.writerow(columns)
  for i in range(coord.shape[0]):
    state = coord['State'][i]
    district=coord['District'][i]
    lat=round(coord['Latitude'][i],4)
    lng=round(coord['Longitude'][i],4)
    url='https://power.larc.nasa.gov/api/temporal/monthly/point?parameters=TS,PRECTOTCORR&community=AG&longitude='+ str(lng) + '&latitude='+ str(lat) + '&format=CSV&start=1997&end=2015'
    response_API = requests.get(url)
    print(response_API.status_code)
    data = response_API.text
    newdata = data[data.find('PARAMETER'):]
    
    l = newdata.split('\n')
    l.pop()
    l.pop(0)
    

    rows_1 = []
    rows_2 = []
    no_of_years=19
    for i in range(no_of_years):
      item=l[i]
      temp=item.split(',')
      temp.insert(0,district)
      temp.insert(0,state)
      #print(temp)
      rows_1.append(temp)
      
      item=l[no_of_years+i]
      rain=item.split(',')
      rain.insert(0,district)
      rain.insert(0,state)
      rows_2.append(rain)

    #print(rows)
    writer1.writerows(rows_1)
    writer2.writerows(rows_2)

temp = pd.read_csv('temp.csv')
rainfall = pd.read_csv('rainfall.csv')

len(pd.unique(coord['District']))

coord.loc[coord['District'].duplicated(),:]

"""### Preprocessing the Weather Files"""

temp.shape,rainfall.shape

#temp.describe()
temp.isnull().sum()

rainfall.isnull().sum()

# print("""Winter, November-April
# Rabi, October-March
# Autumn,  September-October
# Whole Year, Jan-Dec
# Summer, March-June
# Kharif, June-October""")
temp.head()

"""#### Adding Columns for Different Seasons"""

# Calculating season-wise rainfall
def add_seasons(df,prefix):
  df[prefix+'WINTER'] = df[['NOV','DEC','JAN','FEB','MAR','APR']].mean(axis=1)
  df[prefix+'RABI'] = df[['OCT','NOV','DEC','JAN','FEB','MAR']].mean(axis=1)
  df[prefix+'AUTUMN'] = df[['SEP','OCT']].mean(axis=1)
  df[prefix+'SUMMER'] = df[['MAR','APR','MAY','JUN']].mean(axis=1)
  df[prefix+'KHARIF'] = df[['JUN','JUL','AUG','SEP','OCT']].mean(axis=1)
  df.rename(columns = {'ANN':prefix+'ANN'},inplace=True)

add_seasons(temp,"TEMP_")
add_seasons(rainfall,"RAIN_")
temp.head()

temp.rename(columns={'ANN':'TEMP_ANN'},inplace=True)
temp=temp.drop(columns=['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC','PARAMETER'])
temp.head()

rainfall=rainfall.drop(columns=['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC','PARAMETER'])
rainfall.head()

"""# Preprocessing Crop and Soil DB

### Adding Required Columns in SoilDB
"""

# Get crop & soil DB
cropdata = pd.read_csv('/content/Know-and-Grow/Datasets/Crop_DB.csv')
soildata = pd.read_csv('/content/Know-and-Grow/Datasets/Soil_DB.csv')

# Calculating Avg of Acidic, Basic & Neutral components of soil to get pH %
soildata['ACIDIC']=soildata[['AS%','SrAc%','HAc%','MAc%','SlAc%']].sum(axis=1)
soildata['NEUTRAL']=soildata['N%']
soildata['BASIC']=soildata[['MAl%','SlAl%']].sum(axis=1)

soildata=soildata.drop(columns=['AS%','SrAc%','HAc%','MAc%','SlAc%','N%','MAl%','SlAl%'])
soildata.head()

cropdata.head()

cropdata.isnull().sum()

soildata.isnull().sum()

# removing Null Rows
soildata = soildata.dropna(how='any',axis=0)
cropdata = cropdata.dropna(how='any',axis=0)
cropdata.isnull().sum()

"""### Merging Crop_DB and Soil_DB"""

cropdata['State_Name']=cropdata['State_Name'].str.upper()
cropdata['District_Name']=cropdata['District_Name'].str.upper()
soildata['District']=soildata['District'].str.upper()
soildata['State']=soildata['State'].str.upper()

new_df=pd.merge(cropdata,soildata,how='left',left_on=['State_Name','District_Name'],right_on=['State','District'])
new_df=new_df.drop(columns=['State','District'])

new_df.head()

# No. of rows with Null values
new_df.isnull().any(axis=1).sum()

# Print rows with Null Values
null_rows=(new_df[new_df.isna().any(axis=1)])
null_rows.head()

null_rows.State_Name.unique()

null_rows.District_Name.unique()

"""### Merging with Weather Files"""

temp['State']=temp['State'].str.upper()
temp['District']=temp['District'].str.upper()
rainfall['State']=temp['State'].str.upper()
rainfall['District']=temp['District'].str.upper()
final_df=pd.merge(new_df,temp,how='left',left_on=['State_Name','District_Name', 'Crop_Year'],right_on=['State','District', 'YEAR'])

final_df=final_df.drop(columns=['State','District','YEAR'])
final_df.head()

conditions = [
    (final_df['Season'] == 'Kharif'),
    (final_df['Season'] == 'Rabi'),
    (final_df['Season'] == 'Whole Year'),
    (final_df['Season'] == 'Autumn'),
    (final_df['Season'] == 'Summer'),
    (final_df['Season'] == 'Winter'),
    ]
values = [final_df['TEMP_KHARIF'], final_df['TEMP_RABI'], final_df['TEMP_ANN'], final_df['TEMP_AUTUMN'], final_df['TEMP_SUMMER'], final_df['TEMP_WINTER']]
final_df['Temperature'] = np.select(conditions, values)
final_df=final_df.drop(columns=['TEMP_WINTER','TEMP_RABI','TEMP_AUTUMN','TEMP_SUMMER','TEMP_KHARIF','TEMP_ANN'])
final_df.head()

# No. of rows with Null values
final_df.isnull().any(axis=1).sum()

# Merge with rainfall...
final_df=pd.merge(final_df,rainfall,how='left',left_on=['State_Name','District_Name', 'Crop_Year'],right_on=['State','District', 'YEAR'])
final_df=final_df.drop(columns=['State','District','YEAR'])
final_df.head()

conditions = [
    (final_df['Season'] == 'Kharif'),
    (final_df['Season'] == 'Rabi'),
    (final_df['Season'] == 'Whole Year'),
    (final_df['Season'] == 'Autumn'),
    (final_df['Season'] == 'Summer'),
    (final_df['Season'] == 'Winter'),
    ]
values = [final_df['RAIN_KHARIF'], final_df['RAIN_RABI'], final_df['RAIN_ANN'], final_df['RAIN_AUTUMN'], final_df['RAIN_SUMMER'], final_df['RAIN_WINTER']]
final_df['Rainfall'] = np.select(conditions, values)
final_df=final_df.drop(columns=['RAIN_WINTER','RAIN_RABI','RAIN_AUTUMN','RAIN_SUMMER','RAIN_KHARIF','RAIN_ANN'])
final_df.head()

final_df.isnull().any(axis=1).sum()

null_rows=(final_df[final_df.isna().any(axis=1)])
# null_rows.District_Name.nunique()
null_rows.District_Name.unique()

null_rows.loc[null_rows['District_Name']=='AMETHI']

#final_df=final_df.drop(columns=['Crop_Year','State_Name'])
final_df.head()

# Calculating production per unit area for standard comparison of crop ranks
final_df['Prod/Area'] = final_df['Production']/final_df['Area']
final_df.head()

final_df=final_df.drop(columns=['Production','Area'])
final_df.head()

# Combined Master dataset
final_df.to_csv('MasterDB.csv')